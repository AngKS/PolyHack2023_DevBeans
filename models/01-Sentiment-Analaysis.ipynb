{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\stx6\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\stx6\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.126, 'neu': 0.803, 'pos': 0.071, 'compound': -0.34}\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "text = '''A Chinese warship cut off an American warship in the Taiwan Strait while both U.S. and Chinese defense chiefs attended the same conference in Singapore and  days after a Chinese fighter jet \"thumped\" a U.S. Air Force RC-135 in the South China Sea.'''\n",
    "\n",
    "score = sia.polarity_scores(text)\n",
    "print(score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['to fuck', 'fuck your']\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Define your list of extreme negative words\n",
    "extreme_neg_words = [\"fuck\"]\n",
    "\n",
    "def detect_neg_phrases(text):\n",
    "    words = word_tokenize(text)\n",
    "    neg_phrases = []\n",
    "\n",
    "    for i in range(len(words) - 1):\n",
    "        phrase = f\"{words[i]} {words[i + 1]}\"\n",
    "        if sia.polarity_scores(phrase)[\"compound\"] < -0.5 and (words[i] in extreme_neg_words or words[i + 1] in extreme_neg_words):\n",
    "            neg_phrases.append(phrase)\n",
    "\n",
    "    return neg_phrases\n",
    "\n",
    "text = \"I would like to fuck your mother\"\n",
    "print(detect_neg_phrases(text))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"detected\": []}\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": 'perform sentiment analysis and return me the extremely offensive text/phrases without any explanation, in the json format: {\"detected: [<phrase>, <phrase>] \"} '},\n",
    "        {\"role\": \"user\", \"content\": '''Apple Inc. decided to hire John Smith as their new CEO. The event will take place in San Francisco on 2022-07-23.'''},\n",
    "        # {\"role\": \"assistant\", \"content\": 'Please identify and categorize the entities in the provided text.'},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.308, 'neu': 0.554, 'pos': 0.138, 'compound': -0.6705}\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "text = '''This idiot demands 50 Patriot3 systems from 'allies'.  Also demands good fighter jets otherwise counter offensive hard to do because lack of air cover '''\n",
    "\n",
    "score = sia.polarity_scores(text)\n",
    "print(score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"detected\": [\"fuck your mother\"]}\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": 'perform sentiment analysis and return me the extremely offensive text/phrases without any explanation, in the json format: {\"detected: [<phrase>, <phrase>] \"} '},\n",
    "        {\"role\": \"user\", \"content\": '''\"I would like to fuck your mother\"'''},\n",
    "        # {\"role\": \"assistant\", \"content\": 'Please identify and categorize the entities in the provided text.'},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "<OpenAIObject chat.completion id=chatcmpl-7QAUS5QzenX4MVKvbyZFX72eImTBZ at 0x26a98b6fdd0> JSON: {\n  \"id\": \"chatcmpl-7QAUS5QzenX4MVKvbyZFX72eImTBZ\",\n  \"object\": \"chat.completion\",\n  \"created\": 1686471208,\n  \"model\": \"gpt-3.5-turbo-0301\",\n  \"usage\": {\n    \"prompt_tokens\": 54,\n    \"completion_tokens\": 9,\n    \"total_tokens\": 63\n  },\n  \"choices\": [\n    {\n      \"message\": {\n        \"role\": \"assistant\",\n        \"content\": \"{\\\"detected\\\": [\\\"fuck your mother\\\"]}\"\n      },\n      \"finish_reason\": \"stop\",\n      \"index\": 0\n    }\n  ]\n}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"detected\": [\"cut off\", \"thumped\"]}\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": 'perform sentiment analysis and return me the extremely offensive text/phrases without any explanation, in the json format: {\"detected: [<phrase>, <phrase>] \"} '},\n",
    "        {\"role\": \"user\", \"content\": 'A Chinese warship cut off an American warship in the Taiwan Strait while both U.S. and Chinese defense chiefs attended the same conference in Singapore and  days after a Chinese fighter jet \"thumped\" a U.S. Air Force RC-135 in the South China Sea.'},\n",
    "        # {\"role\": \"assistant\", \"content\": 'Please identify and categorize the entities in the provided text.'},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}